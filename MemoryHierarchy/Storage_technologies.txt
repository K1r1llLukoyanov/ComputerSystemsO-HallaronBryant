Much of the success of computer technology systems from the tremendous progress in storage technology.
Early computers had a few kilobytes of random access memory. 


        Random access memory

    Random access memory (RAM) comes in two varieties - static and dynamic. Static RAM (SRAM) is faster and
significantly more expensive than dynamic RAM(DRAM). SRAM is used for cache memories, both on and off
CPU ship. DRAM is used for main memory plus the frame buffer of a graphics systems. Typically, a desktop
system will have no more than tens of megabytes of SRAM, but hundreds and thausands of megabytes of DRAM.


    Static RAM

    SRAM stores each bit in a bistable memory cell. Each cell is emplemented with a six-transistor circuit.
This circuit has the property that it can stay indefinately in either of two different voltage nonfigurations,
or states. Any other state will be unstable - starting from there, the circuit will quickly move toward one
of the stable states. Such a memery cell is analogous to the inverted pendulum.

    Due to its bistable nature, an SRAM memory cell will retain its value indefinately, as long as it kept
powered. Even if disturbance, such as electrical noise, perturbs the voltages, the circuit will return to
the stable value when disturbance is removed.    


            transistors         Relative                                            Relavite
            per bit             access time         Persistent?     Sensitive?          cost        Application
SRAM            6               1 x                     Yes             No           1000x          Cache memory
DRAM            1               10 x                    No              Yes             1x          Main memory


    Dynamic RAM

    DRAM stores each bit as charge on a capacitor. This capacitor is very small - typically around 30 femtofarads,
that is, 30x10^-15 farads. However, farad is very large unit of measure. DRAM storage can be made very dense - each
cell consist of a capacitor and a single access transistor. Unlike SRAM, a DRAM memory cell is very sensitive to any
disturbance. When the capacitor voltage is disturbed, it will never recover. Exposure to light rays will cause the
capacitor voltages to change. In fact, the sensors in digital cameras and camcorders are essentially arrays of DRAM
cells.
    Various sources of leakage current cause DRAM cell to lose its charge within a time period around 10 to 100 milli-
seconds. Fortunately, for computers operating with clock cycle times measured in nanoseconds, this retention time is
quite long. The memory system must periodically refresh every bit of memory by reading it out and then rewriting it.
    
    Summary:

    SRAM is persistent as long as power is applied. Unlike DRAM, no refresh is necessary. SRAM can be accessed faster
than DRAM. SRAM is not sensitive to disturbances such as light and electrical noise. The trade off is that SRAM cells
use more transistors than DRAM and thus have lower densities, are more expensive, and consume more power.

    
    Convential DRAMs

    The cells (bits) in a DRAM chip are partitioned into d supercells, each consisting of w DRAM cells. A d x w DRAM
stores total of d*w bits of information. The supercells are organized as a rectangular array of r words and c columns.
where, rc = d. Each supercell has an address of the form (i,j), where i denotes the row and j denotes the column. DRAM 
chip with d = 16 supercells, r = 4 rows, c = 4 columns, and w = 8 bits in each supercell can store d x w = 16 x 8 = 128 bits.
Information flows in and out of the chip via external connectors called pins. Each pin carries a 1-bit signal. Eight data
pins can transfer 1 byte in or out of the chip, and two addr pins that carry two-bit row and column supercell addresses.
    Each DRAM chip is connected to some circuitry, known as the memory contoller, that can transfer w bits at a time to
and from each DRAM chip. To read the contents of supercell (i, j), the memory contoller sends the row address i to DRAM,
followed by the column address j. The DRAM responds by sending the contents of supercells (i, j) back to the contoller.
The row address i is called a RAS (Row Access Strobe) request. The column address j is called CAS (Column Access Strobe).
Notice that the RAS and CAS requests share the same DRAM address pins.
    For example, to read supercell (2, 1) from 16x8 DRAM, the memory controller sends row address 2. The DRAM responds by
copying the entire content of row 2 into an internal row buffer. Next, the memory contoller sends column address 1. The
DRAM responds by copying 8 bit in supercell (2, 1) from the row buffer and sending them to the memory controller.
    One reason curcuit designers organize DRAMs as two-dimensional arrays instead of linear arrays is to reduce the number
of address pins on the chip. The disadvantage of two-dimensional array organization is that addresses must be sent in two
distinct steps, which increases the access time.


    Memory Modules

    DRAM chips are packaged in memory modules that plug into expansion slots on the main system board (motherboard).
Core i7 systems use the 240 pin dual inline memory module (DIMM), which transfers data to and from memory controller
in 64-bit chunks.
    The example module stores a total 64 MB (megabytes) using eight 64-MBit 8Mx8 DRAM chips, numbered from 0 to 7. Each
supercell stores 1 byte of main memory, and each 64-bit word at byte address A in main memory is represented by the eight
supercells whose corresponding. supercell address (i, j).
    To retrieve a word at memory address A, memory controller converts A to a supercell address (i, j) and sends it to
the memory module, which then broadcast of its (i, j) supercell. Circuitry in the module collects these outputs and forms
them into a 64-bit word, which it returns to the memory controller.
    Main memory can be aggregated by connecting multiple memory modules to the memory contoller. In this case, when the
contoller receives an address A, the contoller selects the module k that contains A, converts A to (i, j) form, and sends
(i, j) to module k.


Practice 6.1 (solution 696):

In the following, let r be the number of rows in a DRAM array, c the number of
columns, b r the number of bits needed to address the rows, and b c the number of
bits needed to address the columns. For each of the following DRAMs, determine
the power-of-2 array dimensions that minimize max(b r , b c ), the maximum number
of bits needed to address the rows or columns of the array.

Organization            r           c           br          bc          max(br, bc)
16x1                    4           4           2           2           2
16x4                    4           4           2           2           2
128x8                   16          8           4           3           4
1024x4                  32          32          5           5           5


    Enchanced DRAMs

    New kinds of DRAM memory appears on market with regularity as manufacturers attemp to keep up rapidly increasing
processors speeds. Each is based on Conventional DRAM cell, with optimizations that improve the speed with which the
basic DRAM cells can be accessed.

  * Fast page mode DRAM (FPM DRAM). A conventional DRAM copies an entire row of supercells into its intenal row buffer,
    uses one, and then discards the rest. FPM DRAM improves on this by allowing consecutive acesses to the same row to
    be served directly from the row buffer. For example, to read four supercells from row i of a conventional DRAM, the
    memory contoller must send four RAS/CAS requests, even though the row address i is the same in each case. To read
    supercell from the same row of FPM DRAM, the memory contoller sends an initial RAS/CAS request, following by three
    CAS requests. The initial RAS/CAS request copies row i into the row buffer and returns the supercell addressed by the
    CAS. The next three supercells are served directly from the row buffer, and thus are returned more quickly than initial
    supecell.

  * Extended data out DRAM (EDO DRAM). An enchanced form of FPM DRAM that allows the individual CAS signal to be spaced
    closer together in time.
  
  * Synchronous DRAM (SDRAM). Conventional, FPM, and EDO DRAMs are asynchronous in the sense that they communicate with
    the memory controller using set of explicit contor signals. SDRAM replaces many of these control signals with rising
    edges of the same external clock signal that drives the memory controller. Without going into detail, the net effect
    is that an SDRAM can output the contents of its supercells at faster rate than its asynchronous counterparts. 

  * Double Data-Rate Synchronous DRAM (DDR). DDR SDRAM is an enchancement of SDRAM that doubles the speed of the DRAM by
    using both clock edges as control signals. Different types of DDR SDRAMs are characterized by the size of a small
    prefetch buffer that increases the effective bandwidth: DDR (2bits), DDR2(4 bits), DDR3(8 bits), DDR4(16 bits).

  * Video RAM (VRAM). Used in the frame buffer of graphics systems. VRAM is similar in spirit to FPM DRAM. Two major
    differences are that (1) VRAM output is produced bu shifting the entire contents of the internal buffer in sequence
    and (2) VRAM allows concurrent reads and writes to the memory. Thus, the system can be painting the screen with pixels
    in the frame buffer (reads) while concurrently writing new values for next update (writes).



    Nonvolatile Memory

    SRAMs and DRAMs are volatile in the sense that they lose thier information if the supply voltage is turned off.
Nonvolatile memories, on the other hand, retain their information even when they are powered off. There are variety
of nonvolatile memories. For historical reasons, they are referred to collectively as read-only memories (ROMs), even
some types of ROMs can be written to as well as read. ROMs are distinguished by the number of times they can be
reprogrammed (written to) and by the mechanism for reprogramming them.
    A programmable ROM (PROM) can be reprogrammed exactly once. PROMs include a sort of fuse with each memory cell that
can be blown once by zapping it with a high current.
    An erasable programmable ROM (EPROM) has a transparent quartz window that permit light to reach the storage cells.
The EPROM cells are cleared to zeros by shining ultaviolet light thought the window. Programming an EPROM is done by
using a special device to write ones into the EPROM. An EPROM can be erased and reprogrammed on the order of 1000 times.
An electrically erasable PROM (EEPROM) is akin to an EPROM, but it does not required a physically separate programming 
device, and thus can be reprogrammed in-place on printed circuit cards. An EEPROM can be reprogrammed on the order of
10^5 times before it wears out.
    Flash memory is a type of nonvolatile memory, based on EEPROMs, that has become an important storage technology.
Flash memories are everywhere, providing fast and durable nonvolatile storage for a slew of electronic devices, including
digital cameras, cell phones, and music players, as well as laptop, desktop, and server computer systems.
    Programs stored in ROM devices are often referred to as firmware. When a computer system is powered up, it runs firmware
stored in ROM. Some systems provide small set of primitive input and output functions in firmware - for example, a PC's
BIOS (basic input/output system) routines. Complicated devices such as grapics cards cand disk drive contollers also rely
on firmware to translate I/O (input/output) requests from the CPU.


    Accessing Main Memory

Data flows back and forth between the processor and the DRAM main memory over shared electrical conduits called buses.
Each transfer of data between the CPU and memory is accomplished with a series of steps called a bus transaction. A read
transaction transfer data from the main memory to CPU, write transaction transfer data from CPU to the main memory.
    A bus is collection of parallel wires that address, data and control signals. Depending on the particular bus design,
data and address signals can share the same set of wires or can use different sets. Also, more than two devides can share
the same bus. The control wires carry signals that synchronize the transaction and identify what kind of transaction is
currently being performed.
    In example computer, there are CPU chip and the DRAM, their buses: system bus and memory bus connected via I/O bridge.
The I/O bridge translates the electrical signals of the system bus into the electric signals of the memory bus. I/O bridge
also connectes the system bus and memory bus to an I/O bus that is shared by I/O devices such as disks and graphics cards.
    Consider what happens when the CPU perform a load operation such as

    movq A, %rax

where the contents of address A are loaded into register %rax. Circuitry on the CPU chip called bus interface interface
initiates a read transaction on the bus. The read transaction consists of three steps. First, the CPU places the address A
on the system bus. The I/O bridge passes the signal along to the memory bus. Next, the main memory senses the address signal
on the memory bus, reads the address from the memory bus, fetches the data from the DRAM, and writes the data to the memory bus.
The I/O bridge translates the memory bus signal into a system bus signal and passes it along the system bus. Finally, the CPU
senses the data on the system bus, reads the data from the bus, and copies the data into register %rax.
    Conversary, when the CPU performs a store operation such as

    movq %rax, A
where the content of register %rax are written to address A, the CPU initiates a write transaction. First the CPU places the
address on the system bus. The memory reads the address from the memory bus and waits for the data to arrive. Next, the CPU
copies the data in %rax to the system bus. Finally, the main memory reads data from the memory bus and stores the bits in the
DRAM.
    
    
    
    Disk storage

Disks are workhorse storage devices that hold enormous amounts of data, on the order of hundres and thausands of gigabytes,
as opposed to the hundred and thausands megabytes in a RAM-based memory. However, it takes on the order of milliseconds to
read information from a disk, a hundred thausands times longer than from DRAM and million times longer than from SRAM.

    Disk geometry

Disks are constructed from platters. Each platter consists of two sides, or surfaces, that coated with magnetic recording
material. A rotating spindle in the center of the platter spins the platter at fixed rotating rate, typically between 5400
and 15000 revolutions per minute (RPM). A disk contain one or more of these platters encased in a sealed container.
    Each surface of platter consists of a collection of concentric rings called tracks. Each track is partitioned into a
collection of sectors. Each sectors contains an equal number of data bits(typically 512 bytes) encoded in the magnetic
material on the sector. Sectors are separated by gaps where no data bits are stored. Gaps store formatting bits that identify
sectors.

    Disk Capacity

The maximum number of bits that can be recorded by a disk is known as its maximum capacity, or simply capacity. Disk capacity
is determined by the following technology factors:

  * Recording density(bits/in): The number of bits that can be squeezed into a 1-inch segment of a track.
  * Track sensity (tracks/in): The number of tracks that can be squeezed into 1-inch segment of the radius
    extending from the center of the platter.
  * Areal density (bits/in^2). The factor of the reconding density and the track density.


    Disk operation

Disks read and write bits stored on the magnetic surface using a read/write head connected to the end of an actuator arm. By
moving the arm back and forth along its radial axis, the drive can position the head over any track on the surface. This
mechanical motion is known as a seek. Once the head is positioned over the desired track, then, as each bit on the track
passes underneath, the head arm can either sense the value of the bit (read the bit) or alter the value of bit (write bit).
Disks with multiple platters platters have a separate heads for each surface. At any point in time, all head are positioned
on the same cylinder.
    The read/write head at the end of the arm flies on this cushion of air over the disk surface at a height of about 0.1
microns and speed of about 80 km/h.
    The access time for a sector has three main components seek time, ratational latency, and transfer time:
    
  * Seek time. The time required to move the arm is called the seek time. The seek time depends on previous position of
    the head and the speed that the arm moves across the surface. The average seek time in modern drives is about 3-9 ms.
  
  * Rotational latency. Once the head is in position over the track, the drive waits for the first bit of the target sector
    to pass under the head. The performace depends on the position of the surface when head arrives at the target track and
    the rotational speed of the disk. In the worst case, the head just misses the target sector and waits for the disk to
    make a full rotation. Thus, the maximum rotational latency, in seconds is given by

    T(max) = 1/RPM * (60 secs/1 min).

  * Transfer time. When the first bit of the target sector is under the head, the drive can begin to read or write the contents
    of the sector. The transfer time for one sector depends on the rotational speed and the number of sectors per track. Thus,
    we can roughly estimate the average transfer time for one sector in seconds.

    T(avg) = 1/RPM * (1/(average#sectors/track)) * (60 secs/1 min)
    

    T(access) = T(avg seek) + T(avg rotation) + T(avg transfer)


    * The time to access the 512 bytes in disk sector is dominated by the seek time and rotation latency.


    Logical Disk Blocks

    To hide disk drive complexity from operating system, modern disk presents a simpler view of their geometry as a sequence
of B sector-size logical blocks, numbered 0, 1, 2, ..., B-1. A small hardware/firmware device in the disk package, called
the disk controller, maintains the mapping between logical block number and actual (physics) disk sector.
    When the operating system wants to perform I/O operation such as reading a disk sector into main memory, it sends a
command to the disk contoller asking it to read a particular logical block number. Firmware on the contoller performs a
fast table lookup that translates the logical block number into a (surface, track, sector) triple that uniquely identifies
the correspoding physical sector.


    Connecting I/O devices.

    Input/Ouput (I/O) devices such as graphics cards, monitors, mice, keyboards, and disks are connected to the CPU and main
memory using the I/O bus. Unlike the system bus and memory buses, which are CPU-specific, I/O buses are designed to be
independent of the underlying CPU.
    Although the I/O bus is slower than the system and memory buses, it can accommodate a wide variety of third-party I/O
devices.

  * A Universal Serial Bus (USB) controller is a conduit for devices attached to a USB bus, which is wildly popular
    standard for connecting a variety of peripheral I/O devices, including keyboards, mice, modems, digital cameras,
    game controllers, printers, external disk drives. USB 3.0 buses have a maximum bandwidth of 625 MB/s. USB 3.1
    buses have a maximum bandwidth 1250 MB/s.
  
  * A graphics card (or adapter) contains hardware and software logic that is responsible for painting the pixels
    on the display monitor on behalf of the CPU.

  * A host bus adapter that connects one or more disks to the I/O bus using a communication protocol defined by a
    particular bus interface. The two most popular such interfaces for disks are SCSI ("squzzy") and SATA. SCSI disks
    are typically faster and more expensive than SATA drives and can support mutiple disks.


    Accessing Disks

    The CPU issues commands to I/O devices using a technique called memory-mapped I/O. In system with memory-mapped I/O,
a block of addresses in the address space is reserved for communication with I/O devices. Each of these addresses space
is known as an I/O port. Each device is associated with (or mapped to) one or more ports when it is attached to the bus.
    As simple example, suppose that the disk controller is mapped to port 0xa0. Then the CPU might initiate a disk read
by executing store instructions to address 0xa0.
    After the disk contoller receives the read command from the CPU, it translates the logical block number to a sector
address, reads the contents of the sector and transfer the contents directly to main memory, without any intervention
from the CPU. This process, whereby a device performs a read and write bus transaction on its own, without any involvement
of the CPU, is known, as direct memory acces (DMA). The transfer of data is known as a DMA transfer.
    After DMA transfer is complete, disk controller nitifies the CPU by sending interrupt signal to the CPU. 

    
    Solid State Disks

    A solid state disk (SSD) is a storage technology, based on flash memory, that in some situations is an attractive altenate
to the conventional rotating disks. An SSD package consists of one or more flash memory chips, which replace the mechanical
drive in a conventional rotating disk, and a flash translation layer, which is hardware/firmware device that plays the same
role as disk controller, translating requests for logical blocks into accesses of the underlying physical device.
    Reading from SSD is faster than writing. The differences between random reading and writing performance is caused by a
fundamental property of the underlying flash memory. For example, flash memory consists of a sequence of B blocks, where each
block consist of P pages. Typically, pages are 512 bytes to 4 KB in size, and block consist of 32-128 pages, with lotal block
size randing from 16KB to 512 KB. Data are read and written in units of pages. A page can be written only after the entire
block to which it belongs has been erased (bits are set to 1). However, once the block is erased, each page in the block can 
be written once with no further erasing. A block wears out after roughly 100000 repeated writes. Once the block wears out, it
can no longer be used.
    Random writes are slower for 2 reasons. First, erasing a block takes a relatively long time, on the order of 1 ms. Second,
if a write operation attempts to modify a page p that contains existing data (i.e, not all ones), then any pages in the same
block with useful data must be copied to a new (erased) block before the write to page p can occur. manufacturers have developed
sophisticated logic in the flash translation layer that attempts to amortize the high cost of erasing blocks and to minimize the
number of internal copies on writes, but it unlikely that random writing will ever perform as well as reading.
    SSDs have a number of advantages over rotating disks. They are built of semiconductors, with no moving parts, and thus have
much faster random access time than rotating disks, use less power, and are more rugged. However, there are some disadvantages.
First, because flash blocks wear out after repeated writes, SSDs have the potential to wear out as well. Wear-leveling logic in 
the flash translation layer attempts to maximize the lifetime of each block by spreading erasures evenly across all blocks.
In practice, the wear-leveling logic is so good that it takes many years for SSDs to wear out. Second, SSDs are more expensive 
per byte than rotating disks, and thus the typical storage capacities are significantly less than rotating disks.


Practice Problem 6.5 (sol. 698):

As we have seen, a potential drawback of SSDs is that the underlying flash memory
can wear out. Intel guarantees about 128 petabytes (128 × 10^15 bytes) of writes 
before the drive wears out. Given this assumption, estimate the lifetime (in years) 
of this SSD for the following workloads: 

A.  Worst case for sequential writes: The SSD is written to continuously at a rate
    of 512 MB/s (the average sequential write throughput of the device).
    
    Answer: (128*10^9)/(512*60*60*24*365) = 7 years

B.  Worst case for random writes: The SSD is written to continuously at a rate
    of 205 MB/s (the average random write throughput of the device).

    Answer: (128*10^15)/(205*60*60*24*365*10^6) = 19 years

C.  Average case: The SSD is written to at a rate of 20 GB/day (the average
    daily write rate assumed by some computer manufacturers in their mobile
    computer workload simulations).
    
    Answer: 128*10^15/(20*365*10^9) = 6,912 years


    Storage Technology Trends

    Different storage Technologies have different price and performance trade-offs.
SRAM is somewhat faster than DRAM, DRAM is much faster than disk. On other hand, fast
storage is always more expensive than slower storage. SRAM cost more per byte than DRAM.
DRAM costs much more per byte than. SSDs split the differences between DRAM and rotating
disk.
    The prices and performance properties of different storage technoligies are chanching
at dramatically different rates.
    It is much easier to increase density, than decrease access time.
    DRAM and disk performance are lagging behind CPU performance. The gap between DRAM and
disk performance and CPU performance is actually widening.